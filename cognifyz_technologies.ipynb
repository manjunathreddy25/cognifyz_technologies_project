{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1lwkqspl-Zti-6DHg-RkMt87o7uY7HPVg",
      "authorship_tag": "ABX9TyMnM8Y+NTn4Z01HpCVrvlUJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manjunathreddy25/cognifyz_technologies_project/blob/main/cognifyz_technologies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Level-1"
      ],
      "metadata": {
        "id": "zNCckJ32Cem5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFPA5rpzCMFF"
      },
      "outputs": [],
      "source": [
        "#Level-1[Task-1]\n",
        "import pandas as pd\n",
        "df= pd.read_csv('/content/drive/MyDrive/Colab_Works/Dataset .csv')\n",
        "# Explore the dataset and identify the number of rows and columns.\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in each column and handle them accordingly.\n",
        "df.info()\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "6aasGqV9DW0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_cuisine_null = df['Cuisines'].isnull()\n",
        "print(df[is_cuisine_null])"
      ],
      "metadata": {
        "id": "b0zpz0RdxjKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Cuisines'] = df['Cuisines'].fillna(df['Cuisines'].mode()[0])\n",
        "df.isnull().sum()\n",
        "# Gives Most Repeated Country Name to Null Values"
      ],
      "metadata": {
        "id": "Rt4jkHdUGVUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling the missing Cuisines using the mode specific to each Country\n",
        "df['Cuisines'] = df.groupby('Country Code')['Cuisines'].transform(lambda x: x.fillna(x.mode()[0]))\n",
        "df.isnull().sum()\n",
        "# Gives Names to Null Values based on Country Code matching to the Cuisines\n",
        "# More Accurate"
      ],
      "metadata": {
        "id": "n--Isb3Outne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to check with what values the null filled\n",
        "target_ids = [\n",
        "    17284105, 17284211, 17284158, 17374552, 17501439,\n",
        "    17606621, 17059060, 17142698, 17616465\n",
        "]\n",
        "filled_na_values_df = df[df['Restaurant ID'].isin(target_ids)]\n",
        "print(filled_na_values_df)"
      ],
      "metadata": {
        "id": "G6UyTVRLzUzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8hESWixJ2FGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform data type conversion if necessary.\n",
        "# Analyze the distribution of the target variable(\"Aggregate rating\") and identify any class imbalances.\n",
        "df['Aggregate rating'].describe()"
      ],
      "metadata": {
        "id": "O7KE4NbLDp4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df['Aggregate rating'].value_counts().sort_index()"
      ],
      "metadata": {
        "id": "cDTEtQCwLFsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Aggregate rating'].skew()"
      ],
      "metadata": {
        "id": "FoQ1nCjnL19k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(df['Aggregate rating'],bins=20,kde=True)\n",
        "plt.title('Distribution of Aggregate Ratings')\n",
        "plt.xlabel('Aggregate Rating')\n",
        "plt.ylabel('Count of Restaurants')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C9CWeNFDNa_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the counts for the whole number ratings\n",
        "df['Rating_Floor'] = df['Aggregate rating'].apply(lambda x: int(x))\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='Rating_Floor', data=df)\n",
        "plt.title('Count of Restaurants by Integer Rating Floor')\n",
        "plt.xlabel('Integer Rating')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-luaOlDEOWpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Level-1[Task-2]\n",
        "# Summarize shape of nummerical data\n",
        "# I have Ingored [restauaran ID, country code] because no need Statistical Measures for these 2 Numerical Columns\n",
        "#  Calculate basic statistical measures (mean,median, standard deviation, etc.) for numerical columns.\n",
        "numerical_cols = ['Longitude', 'Latitude', 'Average Cost for two', 'Aggregate rating', 'Votes']\n",
        "numerical_stats = df[numerical_cols].describe()\n",
        "print(numerical_stats)"
      ],
      "metadata": {
        "id": "f7LIikkATyZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Explore the distribution of categorical variables like \"Country Code,\" \"City,\" and \"Cuisines.\"\n",
        "country_distribution = df['Country Code'].value_counts()\n",
        "print(country_distribution)\n",
        "city_distribution = df['City'].value_counts()\n",
        "print(city_distribution)"
      ],
      "metadata": {
        "id": "2_17iTN1Z-CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuisine_list = df['Cuisines'].str.split(', ').explode()\n",
        "print(cuisine_list)\n",
        "cuisine_distribution = cuisine_list.value_counts()\n",
        "print(cuisine_distribution.head(25))"
      ],
      "metadata": {
        "id": "rV_ZCqgSapz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the top cuisines and cities with the highest number of restaurants.\n",
        "top_cuisines = cuisine_list.value_counts().head(5)\n",
        "print(top_cuisines)\n",
        "\n",
        "# Visualizing the top 10 cuisines\n",
        "def barplot(a):\n",
        "  plt.figure(figsize=(12,6))\n",
        "  sns.barplot(x=a.index,y=a.values)\n",
        "  plt.title('Top 5 Most Frequent Cuisines')\n",
        "  plt.xlabel('Cuisine Type')\n",
        "  plt.ylabel('Number of Restaurants')\n",
        "  plt.xticks(rotation=45,ha='right')\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "print(barplot(top_cuisines))"
      ],
      "metadata": {
        "id": "08KIOVscd0Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_cities = city_distribution.head(5)\n",
        "print(top_cities)\n",
        "print(barplot(top_cities))"
      ],
      "metadata": {
        "id": "lROl66Quggmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Level-1[Task-3]\n",
        "# Visualize the locations of restaurants on a map using latitude and longitude information.\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.scatterplot(x=df['Longitude'],y=df['Latitude'],alpha=0.5,s=90)\n",
        "plt.title('Geographic Distribution of Restaurants')\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bbZbMYcdh46S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze the distribution of restaurants across different cities or countries.\n",
        "country_code_map = {\n",
        "    1: 'India',\n",
        "    14: 'Australia',\n",
        "    30: 'Brazil',\n",
        "    37: 'Canada',\n",
        "    94: 'Indonesia',\n",
        "    148: 'New Zealand',\n",
        "    162: 'Philippines',\n",
        "    166: 'Qatar',\n",
        "    184: 'Singapore',\n",
        "    189: 'South Africa',\n",
        "    191: 'Sri Lanka',\n",
        "    208: 'Turkey',\n",
        "    214: 'UAE',\n",
        "    215: 'United Kingdom',\n",
        "    216: 'United States'\n",
        "}\n",
        "df['Country'] = df['Country Code'].map(country_code_map)\n",
        "total_restaurants = df.shape[0]\n",
        "country_counts = df['Country'].value_counts()\n",
        "country_percentage =(country_counts/total_restaurants)*100\n",
        "country_summary = pd.DataFrame({\n",
        "    'Count':country_counts,\n",
        "    'Percentage':country_percentage\n",
        "}).sort_values(by='Count',ascending=False)\n",
        "print(country_summary.to_markdown(floatfmt='.2f'))"
      ],
      "metadata": {
        "id": "CLSMwaaZnHcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_frequent_country = country_counts.idxmax()\n",
        "#df_top_country = df[df['Country'] == 'India'] --- Here you can use Country name to get Cities List ---\n",
        "df_top_country = df[df['Country'] == most_frequent_country]\n",
        "total_restaurants_in_top_country = df_top_country.shape[0]\n",
        "\n",
        "city_counts = df_top_country['City'].value_counts()\n",
        "city_percentage = (city_counts / total_restaurants_in_top_country) * 100\n",
        "\n",
        "top_cities = city_counts.head(10)\n",
        "top_cities_summary = pd.DataFrame({\n",
        "    'Count': top_cities,\n",
        "    'Percentage': city_percentage.head(10)\n",
        "}).sort_values(by='Count', ascending=False)\n",
        "print(top_cities_summary.to_markdown(floatfmt=\".2f\"))"
      ],
      "metadata": {
        "id": "0bM6kxk5r4GR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine if there is any correlation between the restaurant's location and its rating.\n",
        "correlation_data1= df[[ 'Latitude','Longitude','Aggregate rating']]\n",
        "correlation_data2= df[[ 'Country Code','Aggregate rating']]\n",
        "correlation_matrix1 =correlation_data1.corr()\n",
        "correlation_matrix2 =correlation_data2.corr()\n",
        "''' There is no correlation between the\n",
        "    exact coordinates (Latitude and Longitude) and the rating.\n",
        "'''\n",
        "print(correlation_matrix1['Aggregate rating'])\n",
        "print()\n",
        "''' This Shows that location[Country Code] has higher correlation\n",
        "    with the rating than the coordinates do.\n",
        "    But the 0.282 correlation is a unusual pattern,\n",
        "    showing that a specific country matters,\n",
        "    the Country Code's value is 'meaningless'.\n",
        "'''\n",
        "print(correlation_matrix2['Aggregate rating'])"
      ],
      "metadata": {
        "id": "BPEFHE6iiCQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Level 3"
      ],
      "metadata": {
        "id": "qrK1rEPDVAQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Level 3(Task-1)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df= pd.read_csv('/content/drive/MyDrive/Colab_Works/Dataset .csv')\n",
        "\n",
        "country_code_map = {\n",
        "    1: 'India',\n",
        "    14: 'Australia',\n",
        "    30: 'Brazil',\n",
        "    37: 'Canada',\n",
        "    94: 'Indonesia',\n",
        "    148: 'New Zealand',\n",
        "    162: 'Philippines',\n",
        "    166: 'Qatar',\n",
        "    184: 'Singapore',\n",
        "    189: 'South Africa',\n",
        "    191: 'Sri Lanka',\n",
        "    208: 'Turkey',\n",
        "    214: 'UAE',\n",
        "    215: 'United Kingdom',\n",
        "    216: 'United States'\n",
        "}\n",
        "df['Country'] = df['Country Code'].map(country_code_map)\n",
        "numerical_features = ['Average Cost for two', 'Price range', 'Votes']\n",
        "categorical_features = ['Country', 'Currency', 'Has Table booking', 'Has Online delivery', 'Price range']\n",
        "df['Log_Votes'] = np.log1p(df['Votes'])\n",
        "df['Currency'] = df['Currency'].str.replace(r'\\(.*\\)', '', regex=True).str.strip()\n",
        "final_features = ['Log_Votes', 'Average Cost for two'] + categorical_features\n",
        "\n",
        "X = pd.get_dummies(df[final_features], columns=categorical_features, drop_first=True, dtype=int)\n",
        "y = df['Aggregate rating']\n",
        "X = X.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "y = y.loc[X.index]\n",
        "\n",
        "# Model training and evaluation using appropriate metrics.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=45)\n",
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "    print(f\"\\n* Model Performance Metrics: {model_name} *\")\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "    print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "    print(f\"R-squared (R²): {r2:.4f}\")\n",
        "    return mse, rmse, r2\n",
        "print(\"\\n Random Forest Regressor Model\")\n",
        "rfr_model = RandomForestRegressor(n_estimators=100, random_state=45, n_jobs=-1, max_depth=10, min_samples_leaf=5)\n",
        "rfr_model.fit(X_train, y_train)\n",
        "y_pred_rfr = rfr_model.predict(X_test)\n",
        "evaluate_model(y_test, y_pred_rfr, \"Random Forest Regressor\")\n",
        "\n",
        "print(\"\\n Linear Regression Model\")\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "evaluate_model(y_test, y_pred_lr, \"Linear Regression Model\")\n",
        "\n",
        "print(\"\\n Decision Tree Regressor Model\")\n",
        "dt_model = DecisionTreeRegressor(random_state=45, max_depth=10)\n",
        "dt_model.fit(X_train, y_train)\n",
        "y_pred_dt = dt_model.predict(X_test)\n",
        "evaluate_model(y_test, y_pred_dt, \"Decision Tree Regressor\")\n",
        "\n",
        "'''Random Forest Regressor (RFR): The best model, achieving 94.50% accuracy (R²),\n",
        "   works by averaging the predictions of many Decision Trees to make stable,highly accurate forecasts.\n",
        "'''\n",
        "'''Decision Tree Regressor (DT): The second best model, achieving 93.86% accuracy (R²),\n",
        "   makes predictions by following a simple series of yes/no questions to segment the data.\n",
        "'''\n",
        "'''Linear Regression Model (LR): The worst model, achieving only 72.27%accuracy (R²),\n",
        "   attempts to predict the rating using a single straight line,it shows that relationship in the data is complex and non-linear.\n",
        "'''"
      ],
      "metadata": {
        "id": "FFfj7ZaWVGjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Level 3[Task-2]\n",
        "# Analyzed the relationship between the type of cuisine and the restaurant's rating.\n",
        "cuisines_exploded = df.assign(Cuisine=df['Cuisines'].str.split(', ')).explode('Cuisine')\n",
        "cuisine_analysis = cuisines_exploded.groupby('Cuisine').agg(\n",
        "    Total_Votes=('Votes', 'sum'),\n",
        "    Average_Rating=('Aggregate rating', 'mean'),\n",
        "    Restaurant_Count=('Restaurant ID', 'count')\n",
        ")\n",
        "# Identified the most popular cuisines among customers based on the number of votes.\n",
        "popular_cuisines = cuisine_analysis.sort_values(by='Total_Votes', ascending=False).head(10)\n",
        "print(\"Most Popular Cuisines\")\n",
        "print(popular_cuisines[['Total_Votes', 'Restaurant_Count']].to_markdown(floatfmt=\".0f\"))\n",
        "\n",
        "# Determined if there are any specific cuisines that tend to receive higher ratings.\n",
        "high_rated_cuisines = cuisine_analysis[cuisine_analysis['Restaurant_Count'] >= 50]\n",
        "high_rated_cuisines = high_rated_cuisines.sort_values(by='Average_Rating', ascending=False).head(10)\n",
        "print(\"\\nCuisines Receiving Highest Average Ratings\")\n",
        "print(high_rated_cuisines[['Average_Rating', 'Restaurant_Count', 'Total_Votes']].to_markdown(floatfmt=\".2f\"))"
      ],
      "metadata": {
        "id": "yhWA1UowajT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Level 3[Task 3]\n",
        "# Created visualizations to represent the distribution of ratings using different charts (histogram, barplot).\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# --- 1. Histogram (Distribution Shape) ---\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(df['Aggregate rating'], bins=25, kde=True, color='skyblue', edgecolor='black')\n",
        "plt.title('Distribution of Aggregate Ratings (Histogram)')\n",
        "plt.xlabel('Aggregate Rating')\n",
        "plt.ylabel('Density / Frequency')\n",
        "plt.show()\n",
        "\n",
        "#--- 2. Bar Plot (Discrete Value Counts) ---\n",
        "rating_counts = df['Aggregate rating'].value_counts().sort_index()\n",
        "plt.figure(figsize=(8, 7))\n",
        "sns.barplot(x=rating_counts.index, y=rating_counts.values)\n",
        "plt.title('Frequency of Each Unique Aggregate Rating Value')\n",
        "plt.xlabel('Aggregate Rating Value')\n",
        "plt.ylabel('Number of Restaurants')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5YR8kk3_8qmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "#--- 2. Visualization 1: Average Rating by Cuisine ---\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(\n",
        "    x=high_rated_cuisines.index,\n",
        "    y=high_rated_cuisines['Average_Rating']\n",
        ")\n",
        "plt.title('Top 10 Cuisines by Average Rating', fontsize=14)\n",
        "plt.xlabel('Cuisine Type')\n",
        "plt.ylabel('Average Aggregate Rating')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#--- 3. Visualization 2: Average Rating by City ---\n",
        "city_rating_analysis = df.groupby('City').agg(\n",
        "    Average_Rating=('Aggregate rating', 'mean'),\n",
        "    Restaurant_Count=('Restaurant ID', 'count')\n",
        ")\n",
        "reliable_cities = city_rating_analysis[city_rating_analysis['Restaurant_Count'] >= 10]\n",
        "top_rated_cities = reliable_cities.sort_values(by='Average_Rating', ascending=False).head(10)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(\n",
        "    x=top_rated_cities.index,\n",
        "    y=top_rated_cities['Average_Rating'],\n",
        ")\n",
        "plt.title('Top 10 Cities by Average Restaurant Rating', fontsize=14)\n",
        "plt.xlabel('City')\n",
        "plt.ylabel('Average Aggregate Rating')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X-pWikzyIke8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the relationship between various features and the target variable to gain insights.\n",
        "\n",
        "\n",
        "# Visualization 1: Log_Votes vs. Rating\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(\n",
        "    x='Log_Votes',\n",
        "    y='Aggregate rating',\n",
        "    data=df[df['Aggregate rating'] > 0],  # Removed 0 rating\n",
        "    hue='Price range',\n",
        "    alpha=0.6\n",
        ")\n",
        "plt.title('Relationship between Customer Engagement (Log Votes) and (Rating)')\n",
        "plt.xlabel('Log of Total Votes')\n",
        "plt.ylabel('Aggregate Rating')\n",
        "plt.legend(title='Price Range')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualization 2: Country vs. Rating\n",
        "top_countries = df['Country'].value_counts().head(10).index.tolist()\n",
        "df_top_countries = df[df['Country'].isin(top_countries)]\n",
        "\n",
        "plt.figure(figsize=(8, 7))\n",
        "sns.boxplot(\n",
        "    x='Country',\n",
        "    y='Aggregate rating',\n",
        "    data=df_top_countries\n",
        ")\n",
        "plt.title('\\nDistribution of Aggregate Ratings Across Top Countries')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Aggregate Rating')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Visualization 3: Price Range vs. Rating\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.boxplot(\n",
        "    x='Price range',\n",
        "    y='Aggregate rating',\n",
        "    data=df,\n",
        "    order=[1, 2, 3, 4]\n",
        ")\n",
        "plt.title('\\nRelationship between Price Range and Aggregate Rating')\n",
        "plt.xlabel('Price Range (1: Cheapest to 4: Most Expensive)')\n",
        "plt.ylabel('Aggregate Rating')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k8UsYU0EQUTX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}